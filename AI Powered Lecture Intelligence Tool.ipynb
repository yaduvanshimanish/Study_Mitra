{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPWL0SNgjjUz",
        "outputId": "627cab41-b753-4fde-ec35-6ff9cf6ee248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.12.8-py3-none-any.whl.metadata (180 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faster-whisper\n",
            "  Downloading faster_whisper-1.2.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading yt_dlp-2025.12.8-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp, humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-16.1.0 coloredlogs-15.0.1 ctranslate2-4.6.3 faster-whisper-1.2.1 humanfriendly-10.0 onnxruntime-1.23.2 yt-dlp-2025.12.8\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# --- CELL 1: INSTALLATION ---\n",
        "!pip install gradio transformers sentencepiece torch nltk spacy yt-dlp faster-whisper\n",
        "!python -m spacy download en_core_web_sm\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSfcoE_NikBk",
        "outputId": "31669765-745f-4f90-cb2a-f447ceb5bf0e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ AI Core initialized on cpu\n",
            "â³ Initializing AI Models...\n",
            "   âš ï¸ CUDA failed. Switching to CPU Mode...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "/tmp/ipython-input-3944552552.py:237: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(), css=custom_css, title=\"Team Racoon Tool\") as demo:\n",
            "/tmp/ipython-input-3944552552.py:237: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(), css=custom_css, title=\"Team Racoon Tool\") as demo:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://31358a1bc63736e046.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://31358a1bc63736e046.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- CELL 2: MAIN APP ---\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "import spacy\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import yt_dlp\n",
        "import nltk\n",
        "import nltk.data\n",
        "from transformers import pipeline, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "# --- 1. SAFE DEPENDENCY LOADING ---\n",
        "# NLTK Data Check\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    print(\"â¬‡ï¸ Downloading NLTK resources...\")\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('punkt_tab')\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# Spacy Model Check\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except OSError:\n",
        "    from spacy.cli import download\n",
        "    download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸš€ AI Core initialized on {DEVICE}\")\n",
        "\n",
        "# --- 2. AI ENGINE (MODELS) ---\n",
        "class AI_Engine:\n",
        "    def __init__(self):\n",
        "        print(\"â³ Initializing AI Models...\")\n",
        "\n",
        "        # 1. WHISPER (Audio to Text) - Safe Loading\n",
        "        try:\n",
        "            self.whisper = WhisperModel(\"medium\", device=\"cuda\", compute_type=\"float16\")\n",
        "            print(\"   âœ… Whisper loaded on CUDA\")\n",
        "        except Exception:\n",
        "            print(\"   âš ï¸ CUDA failed. Switching to CPU Mode...\")\n",
        "            self.whisper = WhisperModel(\"medium\", device=\"cpu\", compute_type=\"int8\")\n",
        "\n",
        "        # 2. SUMMARIZER (BART)\n",
        "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "        # 3. TRANSLATOR (M2M100)\n",
        "        self.trans_model_name = \"facebook/m2m100_418M\"\n",
        "        self.trans_tokenizer = M2M100Tokenizer.from_pretrained(self.trans_model_name)\n",
        "        self.trans_model = M2M100ForConditionalGeneration.from_pretrained(self.trans_model_name)\n",
        "        if torch.cuda.is_available():\n",
        "            self.trans_model = self.trans_model.to(\"cuda\")\n",
        "\n",
        "        # 4. QUIZ GENERATOR (T5)\n",
        "        self.qg_pipe = pipeline('text2text-generation', model='valhalla/t5-small-qa-qg-hl', device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "engine = AI_Engine()\n",
        "\n",
        "# --- 3. ACCURACY CALCULATION LOGIC (ON DEMAND) ---\n",
        "def calculate_metrics(segments_data, transcript_text, summary_text, notes_text):\n",
        "    \"\"\"\n",
        "    Ye function tabhi chalega jab user 'Calculate Accuracy' button dabayega.\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“Š Calculating Accuracy Metrics...\")\n",
        "\n",
        "    # 1. Transcription Accuracy (Confidence Score)\n",
        "    trans_score = 0.0\n",
        "    if segments_data:\n",
        "        total_prob = 0\n",
        "        count = 0\n",
        "        for seg in segments_data:\n",
        "            # Avg logprob ko percentage mein badalna\n",
        "            prob = math.exp(seg.avg_logprob)\n",
        "            total_prob += prob\n",
        "            count += 1\n",
        "        trans_score = round((total_prob / count) * 100, 1) if count > 0 else 0.0\n",
        "\n",
        "    # Helper for Text Similarity (Jaccard Index)\n",
        "    def get_text_overlap(source, target):\n",
        "        if not source or not target: return 0.0\n",
        "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "        def tokenize(txt):\n",
        "            return set([t.lower() for t in nltk.word_tokenize(txt) if t.isalnum() and t not in stop_words])\n",
        "\n",
        "        src_tokens = tokenize(source)\n",
        "        tgt_tokens = tokenize(target)\n",
        "\n",
        "        if not tgt_tokens: return 0.0\n",
        "\n",
        "        # Check faithfulness: kitne target words source mein maujood hain\n",
        "        intersection = src_tokens.intersection(tgt_tokens)\n",
        "        return round((len(intersection) / len(tgt_tokens)) * 100, 1)\n",
        "\n",
        "    # 2. Summary Accuracy\n",
        "    summ_score = get_text_overlap(transcript_text, summary_text)\n",
        "\n",
        "    # 3. Notes Accuracy\n",
        "    notes_score = get_text_overlap(transcript_text, notes_text)\n",
        "\n",
        "    return trans_score, summ_score, notes_score\n",
        "\n",
        "# --- 4. PROCESSING FUNCTIONS ---\n",
        "\n",
        "def download_video(url, progress=gr.Progress()):\n",
        "    if not url: return None, \"Please enter a URL.\"\n",
        "    progress(0, desc=\"Downloading...\")\n",
        "    output_path = \"downloads\"\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            filename = ydl.prepare_filename(info)\n",
        "            return filename, f\"âœ… Video downloaded: {info.get('title')}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "def process_transcription(video_path, progress=gr.Progress()):\n",
        "    if not video_path: return None, None, \"Please download a video first.\"\n",
        "\n",
        "    progress(0.2, desc=\"Transcribing...\")\n",
        "    try:\n",
        "        segments_generator, info = engine.whisper.transcribe(video_path, beam_size=5)\n",
        "        # Convert to list to store in State for later accuracy calc\n",
        "        segments = list(segments_generator)\n",
        "        transcript_text = \" \".join([seg.text for seg in segments]).strip()\n",
        "\n",
        "        return transcript_text, segments, \"âœ… Transcription Complete\"\n",
        "    except Exception as e:\n",
        "        return None, None, f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "def generate_summary(text):\n",
        "    if not text: return \"No transcript.\"\n",
        "\n",
        "    # Smart Chunking logic (Sentence based)\n",
        "    sentences = nltk.tokenize.sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sent in sentences:\n",
        "        if len(current_chunk) + len(sent) < 2500:\n",
        "            current_chunk += sent + \" \"\n",
        "        else:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = sent + \" \"\n",
        "    if current_chunk: chunks.append(current_chunk)\n",
        "\n",
        "    summaries = []\n",
        "    for chunk in chunks[:3]:\n",
        "        try:\n",
        "            input_len = len(chunk.split())\n",
        "            max_l = min(150, int(input_len * 0.6))\n",
        "            min_l = min(30, int(input_len * 0.2))\n",
        "            if max_l > min_l:\n",
        "                summary = engine.summarizer(chunk, max_length=max_l, min_length=min_l, do_sample=False)\n",
        "                summaries.append(summary[0]['summary_text'])\n",
        "        except: pass\n",
        "\n",
        "    return \" \".join(summaries)\n",
        "\n",
        "def generate_notes(text):\n",
        "    if not text: return \"No transcript.\"\n",
        "\n",
        "    sentences = nltk.tokenize.sent_tokenize(text)\n",
        "    chunk_size = 7\n",
        "    chunks = [' '.join(sentences[i:i+chunk_size]) for i in range(0, len(sentences), chunk_size)]\n",
        "\n",
        "    notes = []\n",
        "    for chunk in chunks[:5]:\n",
        "        try:\n",
        "            res = engine.summarizer(chunk[:2500], max_length=60, min_length=15, do_sample=False)\n",
        "            point = res[0]['summary_text']\n",
        "            notes.append(f\"- {point}\")\n",
        "        except: pass\n",
        "\n",
        "    return \"### Key Takeaways:\\n\" + \"\\n\".join(notes)\n",
        "\n",
        "def generate_quiz(text):\n",
        "    if not text: return \"No transcript.\"\n",
        "    doc = nlp(text[:5000])\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in ['DATE', 'ORG', 'PERSON', 'GPE', 'EVENT']]\n",
        "    unique_entities = list(set(entities))\n",
        "\n",
        "    if len(unique_entities) < 3:\n",
        "        unique_entities = [token.text for token in doc if token.pos_ == \"NOUN\" and len(token.text) > 4]\n",
        "        unique_entities = list(set(unique_entities))\n",
        "\n",
        "    random.shuffle(unique_entities)\n",
        "    selected_answers = unique_entities[:5]\n",
        "    quiz_output = \"\"\n",
        "\n",
        "    for ans in selected_answers:\n",
        "        for sent in nltk.tokenize.sent_tokenize(text):\n",
        "            if ans in sent and len(sent) < 200:\n",
        "                pattern = re.compile(re.escape(ans), re.IGNORECASE)\n",
        "                input_text = pattern.sub(f\"<hl>{ans}<hl>\", sent)\n",
        "                try:\n",
        "                    q = engine.qg_pipe(f\"generate question: {input_text}\")[0]['generated_text']\n",
        "                    quiz_output += f\"**Q:** {q}\\n**A:** ||{ans}||\\n\\n\"\n",
        "                    break\n",
        "                except: continue\n",
        "    return quiz_output\n",
        "\n",
        "def translate_text(text, target_lang):\n",
        "    if not text: return \"No transcript.\"\n",
        "    lang_map = {\"Hindi\": \"hi\", \"French\": \"fr\", \"English\": \"en\"}\n",
        "    code = lang_map.get(target_lang, \"en\")\n",
        "    tokenizer = engine.trans_tokenizer\n",
        "    model = engine.trans_model\n",
        "    tokenizer.src_lang = \"en\"\n",
        "    encoded = tokenizer(text[:600], return_tensors=\"pt\").to(DEVICE)\n",
        "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(code))\n",
        "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "# --- 5. UI SETUP ---\n",
        "custom_css = \"\"\"\n",
        ".gradio-container { background: linear-gradient(to bottom right, #0F172A, #1E1B4B) !important; }\n",
        "body, .prose, .markdown-text, label, span, p, h1, h2, h3, h4, h5, h6 { color: #F8FAFC !important; font-family: 'Inter', sans-serif; }\n",
        ".markdown-text, .prose p, .prose h1, .prose h2, .prose h3, .prose li, label span { margin-left: 12px !important; }\n",
        "textarea, input, .gr-box, .prose, #output_box, #status_box { background-color: rgba(30, 41, 59, 0.8) !important; color: #FFFFFF !important; border: 1px solid #334155 !important; border-radius: 12px !important; backdrop-filter: blur(5px); }\n",
        "h1 { background: linear-gradient(90deg, #818CF8, #22D3EE); -webkit-background-clip: text; -webkit-text-fill-color: transparent; text-align: center; font-weight: 800 !important; margin-bottom: 10px !important; margin-left: 0 !important; }\n",
        "button.primary { background: linear-gradient(90deg, #4F46E5, #7C3AED) !important; color: white !important; border: none !important; }\n",
        "button.secondary { background-color: #334155 !important; color: #E2E8F0 !important; border: 1px solid #475569 !important; }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), css=custom_css, title=\"Team Racoon Tool\") as demo:\n",
        "\n",
        "    # STATE VARIABLES (To store data for on-demand accuracy check)\n",
        "    video_path_state = gr.State()\n",
        "    transcript_state = gr.State()\n",
        "    segments_state = gr.State()\n",
        "    summary_state = gr.State()\n",
        "    notes_state = gr.State()\n",
        "\n",
        "    # --- HEADER ---\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"# ğŸ“ AI Powered Lecture Intelligence Tool\")\n",
        "\n",
        "    # --- INPUT ---\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, variant=\"panel\"):\n",
        "            gr.Markdown('### 1. Source & Status')\n",
        "            url_input = gr.Textbox(label=\"YouTube URL\", placeholder=\"Paste video link...\", lines=1)\n",
        "            download_btn = gr.Button(\"â¬‡ï¸ Load Video\", variant=\"primary\", size=\"lg\")\n",
        "            status_msg = gr.Textbox(label=\"System Logs\", value=\"System Ready...\", interactive=False, lines=6, elem_id=\"status_box\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown('### 2. Video Preview')\n",
        "            video_player = gr.Video(label=\"Player\", interactive=True, elem_id=\"video_player\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    # --- OUTPUT ---\n",
        "    with gr.Row(variant=\"panel\"):\n",
        "\n",
        "        # CONTROLS\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 3. Controls\")\n",
        "            analyze_btn = gr.Button(\"âœ¨ Transcribe\", variant=\"primary\", size=\"lg\", interactive=False)\n",
        "\n",
        "            gr.Markdown(\"#### Generation Tools\")\n",
        "            summ_btn = gr.Button(\"ğŸ“ Generate Summary\", variant=\"secondary\")\n",
        "            notes_btn = gr.Button(\"ğŸ“Œ Extract Notes\", variant=\"secondary\")\n",
        "            quiz_btn = gr.Button(\"â“ Create Quiz\", variant=\"secondary\")\n",
        "\n",
        "            gr.Markdown(\"#### Translation\")\n",
        "            with gr.Row():\n",
        "                lang_select = gr.Dropdown([\"Hindi\", \"French\", \"English\"], label=\"Target Language\", value=\"Hindi\")\n",
        "                trans_btn = gr.Button(\"GO\", variant=\"secondary\")\n",
        "\n",
        "        # RESULTS TAB\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### 4. Intelligence Output\")\n",
        "            with gr.Tabs():\n",
        "                with gr.TabItem(\"ğŸ“„ Transcript\"):\n",
        "                    transcript_output = gr.Textbox(label=\"Full Text\", lines=15, show_copy_button=True, elem_id=\"output_box\")\n",
        "                with gr.TabItem(\"ğŸ“ Summary\"):\n",
        "                    summary_output = gr.Textbox(label=\"Abstract\", lines=10, show_copy_button=True, elem_id=\"output_box\")\n",
        "                with gr.TabItem(\"ğŸ“Œ Notes\"):\n",
        "                    notes_output = gr.Markdown(elem_id=\"output_box\")\n",
        "                with gr.TabItem(\"â“ Quiz\"):\n",
        "                    quiz_output = gr.Markdown(elem_id=\"output_box\")\n",
        "                with gr.TabItem(\"ğŸŒ Translate\"):\n",
        "                    trans_output = gr.Textbox(label=\"Translation\", lines=10, elem_id=\"output_box\")\n",
        "\n",
        "    # --- ACCURACY SECTION (ON DEMAND) ---\n",
        "    gr.Markdown(\"---\")\n",
        "    with gr.Row(variant=\"panel\"):\n",
        "        with gr.Column(scale=1):\n",
        "            acc_btn = gr.Button(\"ğŸ“Š Calculate Accuracy Scores\", variant=\"primary\", size=\"lg\")\n",
        "            gr.Markdown(\"*Generate Summary & Notes first.*\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            with gr.Row():\n",
        "                acc_trans_out = gr.Number(label=\"Transcription Confidence %\", value=0)\n",
        "                acc_summ_out = gr.Number(label=\"Summary Fidelity %\", value=0)\n",
        "                acc_notes_out = gr.Number(label=\"Notes Relevance %\", value=0)\n",
        "\n",
        "    # --- EVENTS ---\n",
        "\n",
        "    # 1. Download\n",
        "    def on_download(url):\n",
        "        path, msg = download_video(url)\n",
        "        return path, path, msg, gr.update(interactive=(path is not None))\n",
        "\n",
        "    download_btn.click(on_download, inputs=[url_input], outputs=[video_player, video_path_state, status_msg, analyze_btn])\n",
        "\n",
        "    # 2. Transcribe (Saves segments to State)\n",
        "    def on_transcribe(video_path):\n",
        "        text, segments, msg = process_transcription(video_path)\n",
        "        return text, text, segments, msg\n",
        "\n",
        "    analyze_btn.click(on_transcribe,\n",
        "                      inputs=[video_path_state],\n",
        "                      outputs=[transcript_output, transcript_state, segments_state, status_msg])\n",
        "\n",
        "    # 3. Summary (Saves summary to State)\n",
        "    def on_summary(text):\n",
        "        summ = generate_summary(text)\n",
        "        return summ, summ\n",
        "\n",
        "    summ_btn.click(on_summary, inputs=[transcript_state], outputs=[summary_output, summary_state])\n",
        "\n",
        "    # 4. Notes (Saves notes to State)\n",
        "    def on_notes(text):\n",
        "        notes = generate_notes(text)\n",
        "        return notes, notes\n",
        "\n",
        "    notes_btn.click(on_notes, inputs=[transcript_state], outputs=[notes_output, notes_state])\n",
        "\n",
        "    # 5. Quiz & Translate\n",
        "    quiz_btn.click(generate_quiz, inputs=[transcript_state], outputs=[quiz_output])\n",
        "    trans_btn.click(translate_text, inputs=[transcript_state, lang_select], outputs=[trans_output])\n",
        "\n",
        "    # 6. ACCURACY CALCULATION (Separate Trigger)\n",
        "    acc_btn.click(calculate_metrics,\n",
        "                  inputs=[segments_state, transcript_state, summary_state, notes_state],\n",
        "                  outputs=[acc_trans_out, acc_summ_out, acc_notes_out])\n",
        "\n",
        "demo.queue().launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYoWFaUZYfOH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}